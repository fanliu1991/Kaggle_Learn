{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13580 entries, 0 to 13579\n",
      "Data columns (total 21 columns):\n",
      "Suburb           13580 non-null object\n",
      "Address          13580 non-null object\n",
      "Rooms            13580 non-null int64\n",
      "Type             13580 non-null object\n",
      "Price            13580 non-null float64\n",
      "Method           13580 non-null object\n",
      "SellerG          13580 non-null object\n",
      "Date             13580 non-null object\n",
      "Distance         13580 non-null float64\n",
      "Postcode         13580 non-null float64\n",
      "Bedroom2         13580 non-null float64\n",
      "Bathroom         13580 non-null float64\n",
      "Car              13518 non-null float64\n",
      "Landsize         13580 non-null float64\n",
      "BuildingArea     7130 non-null float64\n",
      "YearBuilt        8205 non-null float64\n",
      "CouncilArea      12211 non-null object\n",
      "Lattitude        13580 non-null float64\n",
      "Longtitude       13580 non-null float64\n",
      "Regionname       13580 non-null object\n",
      "Propertycount    13580 non-null float64\n",
      "dtypes: float64(12), int64(1), object(8)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# import data\n",
    "melbourne_data = pd.read_csv(\"melb_data.csv\")\n",
    "melbourne_data.info()\n",
    "\n",
    "price_data = melbourne_data.Price\n",
    "features_data = melbourne_data.drop(['Price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(features_data.dtypes)\n",
    "# select only numeric features\n",
    "numeric_features_data = features_data.select_dtypes(exclude=['object'])\n",
    "train_features, validation_features, train_price, validation_price = train_test_split(numeric_features_data, price_data, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(train_features, validation_features, train_price, validation_price):\n",
    "    forest_model = RandomForestRegressor()\n",
    "    forest_model.fit(train_features, train_price)\n",
    "    forest_prediction = forest_model.predict(validation_features)\n",
    "    mae = mean_absolute_error(validation_price, forest_prediction)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185379.83504874114\n"
     ]
    }
   ],
   "source": [
    "# model based on dropping columns with missing values\n",
    "features_with_missing = [col for col in train_features.columns if train_features[col].isnull().any()]\n",
    "reduced_train_features = train_features.drop(features_with_missing, axis=1)\n",
    "reduced_validation_features  = validation_features.drop(features_with_missing, axis=1)\n",
    "drop_col_mae = score_dataset(reduced_train_features, reduced_validation_features, train_price, validation_price)\n",
    "print drop_col_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184047.36780559647\n"
     ]
    }
   ],
   "source": [
    "# model based on imputation\n",
    "my_imputer = Imputer()\n",
    "imputed_train_features = my_imputer.fit_transform(train_features)\n",
    "imputed_validation_features = my_imputer.transform(validation_features)\n",
    "imputed_mae = score_dataset(imputed_train_features, imputed_validation_features, train_price, validation_price)\n",
    "print imputed_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179156.85753559152\n"
     ]
    }
   ],
   "source": [
    "# model based on imputation with extra columns showing what was imputed\n",
    "imputed_train_features_plus = train_features.copy()\n",
    "imputed_validation_features_plus = validation_features.copy()\n",
    "\n",
    "for col in features_with_missing:\n",
    "    imputed_train_features_plus[col + '_was_missing'] = imputed_train_features_plus[col].isnull()\n",
    "    imputed_validation_features_plus[col + '_was_missing'] = imputed_validation_featurest_plus[col].isnull()\n",
    "\n",
    "imputed_train_features_plus = my_imputer.fit_transform(imputed_train_features_plus)\n",
    "imputed_validation_features_plus = my_imputer.transform(imputed_validation_features_plus)\n",
    "    \n",
    "imputed_plus_mae = score_dataset(imputed_train_features_plus, imputed_validation_features_plus, train_price, validation_price)\n",
    "print imputed_plus_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb            object\n",
       "Address           object\n",
       "Rooms              int64\n",
       "Type              object\n",
       "Method            object\n",
       "SellerG           object\n",
       "Date              object\n",
       "Distance         float64\n",
       "Postcode         float64\n",
       "Bedroom2         float64\n",
       "Bathroom         float64\n",
       "Car              float64\n",
       "Landsize         float64\n",
       "BuildingArea     float64\n",
       "YearBuilt        float64\n",
       "CouncilArea       object\n",
       "Lattitude        float64\n",
       "Longtitude       float64\n",
       "Regionname        object\n",
       "Propertycount    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encodings\n",
    "one_hot_features_data = pd.get_dummies(features_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(features, price):\n",
    "    neg_mean_absolute_error = cross_val_score(RandomForestRegressor(50), features, price, scoring = 'neg_mean_absolute_error').mean()\n",
    "    return -1 * neg_mean_absolute_error\n",
    "\n",
    "mae_numerical_features_only = get_mae(numeric_features_data, price_data)\n",
    "mae_one_hot_encoded = get_mae(one_hot_features_data, price_data)\n",
    "\n",
    "print(mae_numerical_features_only)\n",
    "print(mae_one_hot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the test data is encoded in the same manner as the training data with the align command\n",
    "one_hot_encoded_training_predictors = pd.get_dummies(train_predictors)\n",
    "one_hot_encoded_test_predictors = pd.get_dummies(test_predictors)\n",
    "final_train, final_test = one_hot_encoded_training_predictors.align(one_hot_encoded_test_predictors, join='left', axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
