{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1:\n",
      "   Apples  Bananas\n",
      "0      30       21\n",
      "\n",
      "\n",
      "#2:\n",
      "            Apples  Bananas\n",
      "2017 Sales      35       21\n",
      "2018 Sales      41       34\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Creating, reading, and writing workbook\n",
    "'''\n",
    "# create DataFrame\n",
    "data = {\n",
    "    \"Apples\": [30],\n",
    "    \"Bananas\": [21]\n",
    "       }\n",
    "df = pd.DataFrame(data, columns=[\"Apples\", \"Bananas\"])\n",
    "print(\"#1:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "data = {\n",
    "    \"Apples\": [35, 41],\n",
    "    \"Bananas\": [21, 34]\n",
    "       }\n",
    "df = pd.DataFrame(data, columns=[\"Apples\", \"Bananas\"], index=[\"2017 Sales\", \"2018 Sales\"])\n",
    "print(\"#2:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#3:\n",
      "Flour     4 cups\n",
      "Milk       1 cup\n",
      "Eggs     2 large\n",
      "Spam       1 can\n",
      "Name: Dinner, dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create Series\n",
    "s = pd.Series([\"4 cups\", \"1 cup\", \"2 large\", \"1 can\"], \\\n",
    "              index=[\"Flour\", \"Milk\", \"Eggs\", \"Spam\"], \\\n",
    "              name=\"Dinner\")\n",
    "print(\"#3:\")\n",
    "print(s)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read CSV file\n",
    "df = pd.read_csv(\"../input/wine-reviews/winemag-data_first150k.csv\", \\\n",
    "                 usecols=[\"country\", \"description\", \"designation\", \"points\", \"price\", \"province\", \"region_1\", \"region_2\", \"variety\", \"winery\"])\n",
    "# use the first column in the dataset as index\n",
    "# reviews = pd.read_csv(\"../input/wine-reviews/winemag-data-130k-v2.csv\", index_col=0)\n",
    "\n",
    "# read Excel xls file, and add multiple empty columns\n",
    "df = pd.read_excel(\"../input/publicassistance/xls_files_all/WICAgencies2014ytd.xls\")\n",
    "df[['Unnamed:1', 'Unnamed:2', 'Unnamed:3']] = pd.DataFrame([[np.nan, np.nan, np.nan]], index=df.index)\n",
    "\n",
    "# Save DataFrame as a csv file, with the name \"cows_and_goats.csv\"\n",
    "q6_df = pd.DataFrame({'Cows': [12, 20], 'Goats': [22, 19]}, index=['Year 1', 'Year 2'])\n",
    "q6_df.to_csv(\"cows_and_goats.csv\")\n",
    "\n",
    "# read SQL data into a DataFrame\n",
    "import sqlite3\n",
    " \n",
    "filepath = sqlite3.connect('../input/pitchfork-data/database.sqlite')\n",
    "query = \"SELECT * FROM artists;\"\n",
    "df = pd.read_sql_query(query, filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Indexing, Selecting & Assigning\n",
    "'''\n",
    "\n",
    "import seaborn as sns\n",
    "# Select the \"description\" column from \"reviews\" DataFrame\n",
    "description = reviews[\"description\"]\n",
    "\n",
    "# Select the first value from the \"description\" column of \"reviews\" DataFrame\n",
    "value = description[0]\n",
    "\n",
    "# Select the first row of data (the first record) from \"reviews\" DataFrame\n",
    "# \"iloc\" uses the Python stdlib indexing scheme, where the first element of the range is included and the last one excluded. So \"0:10\" will select entries \"0,...,9\".\n",
    "# \"loc\", meanwhile, indexes inclusively. So \"0:10\" will select entries \"0,...,10\".\n",
    "record = reviews.loc[0] \n",
    "# or record = reviews.iloc[0]\n",
    "\n",
    "# Select the first 10 values from the \"description\" column in \"reviews\" DataFrame\n",
    "values = reviews.loc[:9, \"description\"]  # not 0:10 !!!\n",
    "# the above return a pandas Series\n",
    "values = reviews.loc[:9, [\"description\"]]\n",
    "# the above return a pandas DataFrame\n",
    "\n",
    "# Select the records with the \"1\", \"2\", \"3\", \"5\", and \"8\" row index positions\n",
    "record = reviews.loc[[1,2,3,5,8]]\n",
    "\n",
    "# Select the \"country\", \"province\", \"region_1\", and \"region_2\" columns of the records with the \"0\", \"1\", \"10\", and \"100\" index positions\n",
    "record = reviews.loc[[0,1,10,100], [\"country\", \"province\", \"region_1\", \"region_2\"]]\n",
    "\n",
    "# Select the \"country\" and \"variety\" columns of the first 100 records\n",
    "record = reviews.loc[0:100, [\"country\", \"variety\"]]\n",
    "\n",
    "# Select wines made in \"Italy\"\n",
    "italy_wine = reviews.loc[reviews[\"country\"] == \"Italy\"]\n",
    "\n",
    "# Select wines whose \"region_2\" is not \"NaN\"\n",
    "nan_region2 = reviews.loc[reviews[\"region_2\"].notnull()]\n",
    "# Select wines whose \"region_2\" is \"NaN\"\n",
    "nan_region2 = reviews.loc[reviews[\"region_2\"].isnull()]\n",
    "\n",
    "# Select the \"points\" column\n",
    "points = reviews.loc[:, \"points\"]\n",
    "\n",
    "# Select the \"points\" column for the first 1000 wines\n",
    "points = reviews.loc[:1000, \"points\"]\n",
    "\n",
    "# Select the \"points\" column for the last 1000 wines\n",
    "points = reviews[-1000:][\"points\"]\n",
    "\n",
    "# Select the \"points\" column, but only for wines made in Italy\n",
    "italy_points = reviews.loc[reviews[\"country\"] == \"Italy\", \"points\"]\n",
    "\n",
    "# Select the \"country\" column, but only when said \"country\" is France or Italy, and the \"points\" column is greater than or equal to 90\n",
    "good_wine = reviews.loc[reviews[\"points\"] >= 90, [\"country\"]]\n",
    "good_wine_country = good_wine.loc[(reviews[\"country\"] == \"Italy\") | (reviews[\"country\"] == \"France\"), \"country\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Summary functions and maps workbook\n",
    "'''\n",
    "# What is the median of the \"points\" column?\n",
    "points_median = reviews[\"points\"].median()\n",
    "\n",
    "# What countries are represented in the dataset?\n",
    "countries = reviews[\"country\"].unique()\n",
    "\n",
    "# What countries appear in the dataset most often?\n",
    "countries_count = reviews[\"country\"].value_counts()\n",
    "'''\n",
    "US        54504\n",
    "France    22093\n",
    "          ...  \n",
    "China         1\n",
    "Egypt         1\n",
    "Name: country, Length: 43, dtype: int64\n",
    "'''\n",
    "most_ofter_country = countries_count[0]\n",
    "'''\n",
    "54504\n",
    "'''\n",
    "most_ofter_country = countries_count.index.values[0]\n",
    "'''\n",
    "US\n",
    "'''\n",
    "\n",
    "# Remap the \"price\" column by subtracting the median price. Use the \"Series.map\" method.\n",
    "price_median = reviews[\"price\"].median()\n",
    "reviews[\"price_diff_median\"] = reviews[\"price\"].map(lambda p: p - price_median)\n",
    "\n",
    "# Which wine in is the \"best bargain\", e.g., which wine has the highest points-to-price ratio in the dataset?\n",
    "reviews[\"points_price_ratio\"] = reviews[\"points\"].divide(reviews[\"price\"])\n",
    "highest_points_price_ratio_wine = reviews.loc[reviews[\"points_price_ratio\"].argmax()][\"title\"]\n",
    "# reviews.loc[(reviews.points / reviews.price).argmax()].title\n",
    "\n",
    "# Create a \"Series\" counting how many times words \"tropical\" and \"fruity\" appears in the \"description\" column in the dataset.\n",
    "tropical_wine = reviews[\"description\"].map(lambda r: \"tropical\" in r).value_counts()\n",
    "'''\n",
    "False    126364\n",
    "True       3607\n",
    "Name: description, dtype: int64\n",
    "'''\n",
    "fruity_wine = reviews.description.map(lambda r: \"fruity\" in r).value_counts()\n",
    "tropical_fruity_count = pd.Series([tropical_wine[True], fruity_wine[True]], index=[\"tropical\", \"fruity\"])\n",
    "\n",
    "# What combination of countries and varieties are most common?\n",
    "country_variety_notNull = reviews.loc[(reviews[\"country\"].notnull()) & (reviews[\"variety\"].notnull())]\n",
    "country_variety_combination = country_variety_notNull.apply(lambda row: row[\"country\"] + \" - \" + row[\"variety\"], axis=\"columns\")\n",
    "'''\n",
    "0               Italy - White Blend\n",
    "1         Portugal - Portuguese Red\n",
    "                   ...           \n",
    "129969          France - Pinot Gris\n",
    "129970      France - Gew√ºrztraminer\n",
    "Length: 129907, dtype: object\n",
    "'''\n",
    "common = country_variety_combination.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Grouping and Sorting\n",
    "'''\n",
    "# Create a \"Series\" whose index is the \"taster_twitter_handle\" category from the dataset, and whose values count how many reviews each person wrote.\n",
    "common_wine_reviewers = reviews.groupby(\"taster_twitter_handle\").taster_twitter_handle.count()\n",
    "# === reviews[\"taster_twitter_handle\"].value_counts()\n",
    "\n",
    "# Create a \"Series\" whose index is wine prices and whose values is the maximum number of points. Sort the valeus by price, ascending.\n",
    "best_wine = reviews.groupby(\"price\").points.max().sort_index()\n",
    "\n",
    "# Create a \"DataFrame\" whose index is the \"variety\" category and whose values are the count, \"min\" and \"max\" prices.\n",
    "wine_price_extremes = reviews.groupby(\"variety\").price.agg([len, min, max])\n",
    "\n",
    "# Create a \"DataFrame\" whose index are country and province and whose values is the wine with highest points.\n",
    "best_wine = reviews.groupby([\"country\", \"province\"]).apply(lambda df: df.loc[df.points.argmax()])\n",
    "# MultiIndex !!! \n",
    "\n",
    "# Create a \"Series\" whose index is reviewers and whose values is the average review score given out by that reviewer.\n",
    "reviewer_mean_ratings = reviews.groupby(\"taster_name\").points.mean()\n",
    "\n",
    "# Create a \"DataFrame\" whose index is wine varieties and whose values are columns with the \"min\" and the \"max\" price of wines of this variety.\n",
    "# Sort in descending order based on \"min\" first, \"max\" second.\n",
    "wine_price_range = reviews.groupby(\"variety\").price.agg([min, max]).sort_values(by=[\"min\", \"max\"], ascending=False)\n",
    "# to sort by index values, use the companion method sort_index. This method has the same arguments and default order.\n",
    "wine_price_range = reviews.groupby(\"variety\").price.agg([min, max]).sort_index()\n",
    "\n",
    "# Create a \"Series\" whose index is a \"MultiIndex\"of \"{country, variety}\" pairs. \n",
    "# Sort the values in the \"Series\" in descending order based on wine count.\n",
    "country_variety_pairs_series = reviews.groupby([\"country\", \"variety\"]).country.count().sort_values(ascending=False)\n",
    "# Create a \"DataFrame\" under same requirement\n",
    "country_variety_pairs_df = reviews.groupby([\"country\", \"variety\"]).country.agg([len]).sort_values(by=\"len\", ascending=False)\n",
    "\n",
    "# Converting MultiIndex back to a regular index.\n",
    "country_variety_pairs_df.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data types, Missing data and Replacing\n",
    "'''\n",
    "# What is the data type of the index in the dataset?\n",
    "index_type = reviews.index.dtype\n",
    "\n",
    "# What is the data type of the \"points\" column in the dataset?\n",
    "points_type = reviews[\"points\"].dtypes\n",
    "\n",
    "# What is the data type of every column in the dataset?\n",
    "columns_type = reviews.dtypes\n",
    "\n",
    "# Create a \"Series\" from entries in the \"price\" column, but convert the entries to strings\n",
    "price_series = reviews[\"price\"].astype(\"str\")\n",
    "\n",
    "# Create a \"Series\"that, for each review in the dataset, states whether the wine reviewed has a null \"price\".\n",
    "null_price = reviews[reviews[\"price\"].isnull()]\n",
    "# === reviews.loc[reviews[\"price\"].isnull()]\n",
    "\n",
    "# Create a \"Series\" counting the number of times each value occurs in the \"region_1\" field. \n",
    "# Replace missing values with \"Unknown\". Sort in descending order.\n",
    "region1_count = reviews[\"region_1\"].fillna(\"Unknown\").value_counts().sort_values(ascending=False)\n",
    "\n",
    "# Create a \"pandas\" \"Series\" showing how many times each of the columns in the dataset contains null values.\n",
    "null_count = reviews.isnull().sum()\n",
    "# Boolean data types has a property that \"False\" gets treated as 0 and \"True\" as 1 when performing math on the values.\n",
    "# Thus, the \"sum()\" of a list of boolean values will return how many times \"True\" appears in that list.\n",
    "\n",
    "# Create a \"Series\" replacing values \"Invalid\" with \"Unknown\" in the \"region_1\" field.\n",
    "region1_replace = reviews[\"region_1\"].replace(\"Invalid\", \"Unknown\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Renaming and Combining workbook\n",
    "'''\n",
    "# Rename `region_1` and `region_2` columns to `region` and `locale`.\n",
    "reviews.rename(columns={'region_1': 'region', 'region_2': 'locale'})\n",
    "\n",
    "# Set the index name in the dataset to `wines`.\n",
    "reviews.index.names = ['wines']\n",
    "\n",
    "# Create a `DataFrame` of products mentioned on \"gaming_products\" and \"movie_products\"\n",
    "products = pd.concat([gaming_products, movie_products])\n",
    "\n",
    "# Both tables \"powerlifting_meets\" and \"powerlifting_competitors\" include column `MeetID`, a unique key for each meet (competition) included in the database.\n",
    "# Generate a dataset combining the two tables into one.\n",
    "combine_tables = powerlifting_meets.set_index(\"MeetID\").join(powerlifting_competitors.set_index(\"MeetID\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Method chaining workbook\n",
    "'''\n",
    "'''\n",
    "chess_games = ['id', 'rated', 'created_at', 'last_move_at', 'turns', 'victory_status',\n",
    "               'winner', 'increment_code', 'white_id', 'white_rating', 'black_id',\n",
    "               'black_rating', 'moves', 'opening_eco', 'opening_name', 'opening_ply']\n",
    "'''\n",
    "# Use the `winner` column to create a `Series` showing ratio of white wins, black wins and tie.\n",
    "result_ratio = chess_games[\"winner\"].value_counts() / len(chess_games)\n",
    "\n",
    "# The `opening_name` field has information such as `Queen's Pawn Game` and `Queen's Pawn Game: Zukertort Variation`.\n",
    "# Parse the `opening_name` field and generate a `Series` counting each of the \"opening archetypes\" used times.\n",
    "striped_opening = chess_games[\"opening_name\"].map(lambda n: n.split(\":\")[0].split(\"|\")[0].split(\"#\")[0].strip())\n",
    "opening_count = striped_opening.value_counts()\n",
    "\n",
    "# Group the games by `{white_id, victory_status}` and count the times of each ended result for each white player.\n",
    "white_victory_status = chess_games.groupby([\"white_id\", \"victory_status\"]).victory_status.agg([len])\n",
    "white_victory_status = white_victory_status.reset_index().rename(columns={\"len\": \"n\"})\n",
    "# === chess_games.assign(n=0).groupby(['white_id', 'victory_status']).n.apply(len).reset_index()\n",
    "\n",
    "# Create a `DataFrame` like the one in the previous exercise, but only include users who are in the top 20 users by number of games played. \n",
    "top_20 = chess_games[\"white_id\"].value_counts().head(20).index\n",
    "'''\n",
    "Index(['taranga', 'chess-brahs', 'a_p_t_e_m_u_u', 'bleda', 'ssf7',\n",
    "       'hassan1365416', 'khelil', 'saviter', 'anakgreget', '1240100948',\n",
    "       'ozguragarr', 'ivanbus', 'vladimir-kramnik-1', 'vovkakuz',\n",
    "       'thegrim123321', 'king5891', 'mastersalomon', 'islam01', 'ozil17',\n",
    "       'artem555'],\n",
    "      dtype='object')\n",
    "'''\n",
    "white_victory_status_top20 = white_victory_status.loc[white_victory_status[\"white_id\"].isin(top_20)]\n",
    "\n",
    "# Generate a `Series` whose index is a `MultiIndex` based on the `{koi_pdisposition, koi_disposition}` fields,\n",
    "# and whose values is a count of how many times each possible combination occurred.\n",
    "combination_count = kepler.groupby([\"koi_pdisposition\", \"koi_disposition\"]).koi_pdisposition.count()\n",
    "\n",
    "# The `points` column in the `wine_reviews` dataset is measured on a 20-point scale between 80 and 100.\n",
    "# Create a `Series` which normalizes the ratings to fit on a 1-to-5 scale, i.e., 80 -> 1, 100 -> 5\n",
    "# Set the `Series` name to \"Wine Ratings\", and sort by index value (ascending).\n",
    "normalized_points = wine_reviews[\"points\"].dropna().map(lambda p: (p-80) / 4.0).sort_index()\n",
    "normalized_points.index.names = ['Wine Ratings']\n",
    "\n",
    "# Create a `Series` counting how many ramens earned each of the possible scores in the dataset.\n",
    "# Convert the `Series` to the `float64` dtype and drop ramen whose rating is \"Unrated\".\n",
    "# Set the name of the `Series` to \"Ramen Ratings\". Sort by index value (ascending).\n",
    "ramen_ratings_count = ramen_reviews.loc[ramen_reviews[\"Stars\"] != \"Unrated\", \"Stars\"].astype(\"float64\")\n",
    "# ramen_reviews[\"Stars\"].replace('Unrated', None).dropna().astype(\"float64\")\n",
    "ramen_ratings_count = ramen_ratings_count.value_counts().sort_index()\n",
    "ramen_ratings_count.index.names = [\"Ramen Ratings\"]\n",
    "\n",
    "# Modify answer to the previous exercise by rounding review scores to the nearest half-point (so 0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, or 5).\n",
    "ramen_ratings = ramen_reviews[\"Stars\"].replace('Unrated', None).dropna().astype(\"float64\")\n",
    "ramen_ratings_rounding = ramen_ratings.map(lambda v: int(v) if v - int(v) < 0.5 else int(v) + 0.5)\n",
    "ramen_ratings_rounding_count = ramen_ratings_rounding.value_counts().sort_index()\n",
    "ramen_ratings_rounding_count.index.names = [\"Ramen Ratings\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
